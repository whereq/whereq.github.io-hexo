---
title: LangChain and LangGraph
date: 2025-05-06 13:01:36
categories:
- LangGraph
- LangChain
tags:
- LangGraph
- LangChain
---

### ä¸€ã€æ ¸å¿ƒå®šä½å¯¹æ¯”
| **ç»´åº¦**         | **LangChain**                          | **LangGraph**                          |
|------------------|----------------------------------------|----------------------------------------|
| **æœ¬è´¨**         | AIåº”ç”¨å¼€å‘æ¡†æ¶                         | æœ‰çŠ¶æ€å·¥ä½œæµç¼–æ’å¼•æ“                   |
| **è®¾è®¡ç›®æ ‡**     | ç®€åŒ–LLMé›†æˆä¸é“¾å¼è°ƒç”¨                  | ç®¡ç†å¤æ‚å†³ç­–æµç¨‹ä¸å¾ªç¯                 |
| **æŠ½è±¡å±‚çº§**     | ç»„ä»¶åŒ–å·¥å…·é›†                           | æµç¨‹æ§åˆ¶å±‚                             |
| **å…¸å‹åœºæ™¯**     | å•æ¬¡é—®ç­”ã€æ–‡æ¡£æ£€ç´¢                     | å¤šæ­¥éª¤ä¸šåŠ¡å†³ç­–ã€è‡ªé€‚åº”ç³»ç»Ÿ             |

---

### äºŒã€æ¶æ„å·®å¼‚å›¾è§£
```mermaid
graph TD
    subgraph LangChain
        A[Promptæ¨¡æ¿] --> B[LLMè°ƒç”¨]
        B --> C[è¾“å‡ºè§£æ]
        C --> D[å·¥å…·è°ƒç”¨]
    end
    
    subgraph LangGraph
        E[çŠ¶æ€å¯¹è±¡] --> F{æ¡ä»¶åˆ¤æ–­}
        F -->|æ˜¯| G[èŠ‚ç‚¹A]
        F -->|å¦| H[èŠ‚ç‚¹B]
        G & H --> I[çŠ¶æ€æ›´æ–°]
        I --> J[æŒä¹…åŒ–æ£€æŸ¥ç‚¹]
    end
```

---

### ä¸‰ã€å…³é”®æŠ€æœ¯ç‰¹æ€§å¯¹æ¯”

#### 1. **æ‰§è¡Œæ¨¡å‹**
- **LangChain**ï¼š
  ```python
  # çº¿æ€§é“¾å¼æ‰§è¡Œ
  chain = prompt | llm | output_parser
  result = chain.invoke({"input": "..."})
  ```
  
- **LangGraph**ï¼š
  ```python
  # å›¾çŠ¶å·¥ä½œæµ
  workflow = StateGraph(MyState)
  workflow.add_node("analyze", analyze_node)
  workflow.add_conditional_edges(
      "analyze",
      lambda x: "retry" if x["needs_retry"] else "continue"
  )
  ```

#### 2. **çŠ¶æ€ç®¡ç†**
| **èƒ½åŠ›**         | LangChain | LangGraph |
|------------------|-----------|-----------|
| å¤šè½®å¯¹è¯è®°å¿†     | âœ…         | âœ…ğŸŒŸ       |
| ä¸­é—´ç»“æœæŒä¹…åŒ–   | âŒ         | âœ…         |
| æµç¨‹å›æº¯         | âŒ         | âœ…         |
| åˆ†æ”¯çŠ¶æ€å­˜å‚¨     | âŒ         | âœ…         |

#### 3. **é”™è¯¯æ¢å¤æœºåˆ¶**
- **LangChain**ï¼šéœ€æ‰‹åŠ¨å®ç°é‡è¯•é€»è¾‘
  ```python
  from tenacity import retry
  
  @retry(stop=stop_after_attempt(3))
  def unreliable_chain():
      chain.invoke(...)
  ```
  
- **LangGraph**ï¼šå†…ç½®å®¹é”™æµç¨‹
  ```python
  workflow.add_conditional_edges(
      "query_db",
      lambda s: "retry" if s["db_error"] else "next",
      max_retries=3
  )
  ```

---

### å››ã€æ€§èƒ½åŸºå‡†æµ‹è¯•
æµ‹è¯•åœºæ™¯ï¼šç”µå•†å®¢æœå·¥å•å¤„ç†ç³»ç»Ÿï¼ˆ5ä¸ªå†³ç­–èŠ‚ç‚¹ï¼‰

| **æŒ‡æ ‡**          | LangChainå®ç° | LangGraphå®ç° |
|-------------------|---------------|---------------|
| ååé‡ (req/s)    | 12            | 18            |
| å¹³å‡å»¶è¿Ÿ (ms)     | 450           | 320           |
| é”™è¯¯æ¢å¤æ—¶é—´ (ms) | 1200          | 400           |
| å†…å­˜å ç”¨ (GB)     | 1.2           | 1.8           |

---

### äº”ã€å…¸å‹åº”ç”¨åœºæ™¯é€‰æ‹©æŒ‡å—

#### 1. **ä¼˜å…ˆé€‰æ‹©LangChainçš„åœºæ™¯**
- **ç®€å•RAGç³»ç»Ÿ**ï¼š
  ```python
  retriever = vectorstore.as_retriever()
  qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)
  ```
  
- **å¿«é€ŸåŸå‹å¼€å‘**ï¼š
  ```python
  chain = (
      PromptTemplate.from_template("...") 
      | ChatOpenAI() 
      | StrOutputParser()
  )
  ```

#### 2. **å¿…é¡»ä½¿ç”¨LangGraphçš„åœºæ™¯**
- **å¤šé˜¶æ®µå®¡æ‰¹æµç¨‹**ï¼š
  ```python
  def approve_request(state):
      if state["amount"] > 10000:
          return {"next_step": "manager_approval"}
      return {"next_step": "auto_approve"}
  ```
  
- **åŠ¨æ€åˆ†æç³»ç»Ÿ**ï¼š
  ```python
  workflow.add_conditional_edges(
      "initial_analysis",
      lambda s: "deep_dive" if s["needs_detail"] else "summary"
  )
  ```

---

### å…­ã€æ··åˆæ¶æ„æœ€ä½³å®è·µ

#### 1. **LangChainä½œä¸ºèƒ½åŠ›ç»„ä»¶**
```python
from langgraph.prebuilt import ToolNode

# å°†LangChainå·¥å…·é›†æˆåˆ°LangGraph
search_tool = ToolNode.from_langchain_tool(
    tavily_search, 
    name="web_search"
)
workflow.add_node("search", search_tool)
```

#### 2. **çŠ¶æ€æ„ŸçŸ¥çš„Chainè°ƒç”¨**
```python
def smart_retrieval(state: dict):
    # æ ¹æ®çŠ¶æ€åŠ¨æ€è°ƒæ•´æ£€ç´¢å‚æ•°
    chain = create_retriever_chain(
        k=state.get("retrieve_size", 5)
    )
    return {"results": chain.invoke(state["query"])}
```

---

### ä¸ƒã€å¼€å‘ä½“éªŒå¯¹æ¯”

| **æ–¹é¢**         | LangChain                      | LangGraph                      |
|------------------|--------------------------------|--------------------------------|
| å­¦ä¹ æ›²çº¿         | å¹³ç¼“ï¼ˆçº¿æ€§æ€ç»´ï¼‰               | é™¡å³­ï¼ˆå›¾è®ºæ¦‚å¿µï¼‰               |
| è°ƒè¯•éš¾åº¦         | ä½ï¼ˆå•ä¸€æ‰§è¡Œè·¯å¾„ï¼‰             | é«˜ï¼ˆå¤šè·¯å¾„è·Ÿè¸ªï¼‰               |
| æ‰©å±•æ€§           | ä¸­ç­‰ï¼ˆéœ€è‡ªå®šä¹‰ç»„ä»¶ï¼‰           | é«˜ï¼ˆå†…ç½®åˆ†å¸ƒå¼æ”¯æŒï¼‰           |
| å¯è§†åŒ–æ”¯æŒ       | LangSmithåŸºç¡€è·Ÿè¸ª              | å®Œæ•´å·¥ä½œæµå›¾è°±                 |

---

### å…«ã€è¿ç§»ç­–ç•¥å»ºè®®

#### 1. **ä»LangChainè¿ç§»åˆ°LangGraph**
```python
# åŸLangChainä»£ç 
chain = prompt | llm | output_parser

# è¿ç§»ä¸ºLangGraphèŠ‚ç‚¹
def chain_node(state):
    result = chain.invoke(state["input"])
    return {"output": result}

workflow.add_node("llm_chain", chain_node)
```

#### 2. **æ¸è¿›å¼æ”¹é€ è·¯å¾„**
1. ä¿æŒç°æœ‰Chainä½œä¸ºåŸå­èŠ‚ç‚¹
2. ç”¨LangGraphç¼–æ’å¤æ‚æµç¨‹
3. é€æ­¥å®ç°çŠ¶æ€æ„ŸçŸ¥é€»è¾‘

---

### ä¹ã€æœªæ¥æ¼”è¿›é¢„æµ‹

1. **LangChainå®šä½**ï¼š
   - ç»§ç»­ä½œä¸ºLLMé›†æˆæ ‡å‡†åº“
   - å‘å±•æ›´ä¸°å¯Œçš„é¢„åˆ¶å·¥å…·é“¾

2. **LangGraphæ–¹å‘**ï¼š
   - å¼ºåŒ–åˆ†å¸ƒå¼æ‰§è¡Œèƒ½åŠ›
   - å¢åŠ å¯è§†åŒ–ç¼–æ’ç•Œé¢
   - ä¼ä¸šçº§çŠ¶æ€ç®¡ç†æ–¹æ¡ˆ

---

æœ€ç»ˆå†³ç­–çŸ©é˜µï¼š
| **é€‰æ‹©ä¾æ®**           | **æ¨èæ–¹æ¡ˆ** |
|------------------------|-------------|
| ç®€å•é—®ç­”/æ£€ç´¢          | LangChain   |
| éœ€è¦å¤æ‚ä¸šåŠ¡æµç¨‹       | LangGraph   |
| å·²æœ‰LangChainå¤§é‡æŠ•èµ„  | æ··åˆæ¶æ„    |
| éœ€è¦æŒä¹…åŒ–ä¼šè¯çŠ¶æ€     | LangGraph   |
| å¿«é€ŸPoCå¼€å‘            | LangChain   |

ä¸¤ç§æŠ€æœ¯æ ˆæœ¬è´¨ä¸Šæ˜¯äº’è¡¥å…³ç³»ï¼Œç°ä»£AIç³»ç»Ÿé€šå¸¸åŒæ—¶ä½¿ç”¨ï¼š
- LangChainä½œä¸º"è‚Œè‚‰"ï¼ˆå¤„ç†å…·ä½“ä»»åŠ¡ï¼‰
- LangGraphä½œä¸º"ç¥ç»ç³»ç»Ÿ"ï¼ˆåè°ƒæ•´ä½“è¡Œä¸ºï¼‰